{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dymochro/MOCHA/blob/main/MOCHA_ColabNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsg-rAgwpeSC"
      },
      "source": [
        "# MOCHA-FRAP\n",
        "MOCHA-FRAP is a quantitative half-FRAP approach to assess if molecules in a structure of interest undergo liquid-liquid phase separation (LLPS) driven by multivalent interactions, or if they undergo low-valency interactions with spatially clustered binding sites (ICBS) on an immobile scaffold. MOCHA-FRAP distinguishes both models by quantifying the apparent energy barrier at the interface of the structure of interest. The theoretical and experimental background can be found in <a href=\"https://www.nature.com/articles/s41467-022-35430-y\">Muzzopappa et al., 2022</a>.\n",
        "\n",
        "**Before performing half-FRAP experiments, check Supplementary Note 2 in <a href=\"https://www.nature.com/articles/s41467-022-35430-y\">Muzzopappa et al., 2022</a> for advice on how to perform experiments that are suitable for the workflow described here.**\n",
        "\n",
        "**This Colab Notebook is intended to provide a user-friendly interface to quantitatively analyze half-FRAP data. It consists of two parts:**\n",
        "- **Analysis of individual experiments:** *Allows you to segment the nucleus/cytoplasm and the bleached structure of interest in an image stack, to retrieve the raw intensity traces, and to perform the corresponding normalization. The results can then be downloaded as .csv file.*\n",
        "- **Analysis of dataset with normalized curves:** *Allows you to upload the .csv files generated in the previous step, to plot the average curve, to determine the dip depth in the non-bleached half, and to decide if the bleached protein undergoes LLPS or ICBS.*\n",
        "\n",
        "*Version: 1.65*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EymKmRzbpaCi"
      },
      "source": [
        "## **Part I: Analysis of individual experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HdUeJGI1SIt"
      },
      "outputs": [],
      "source": [
        "#@title Import functions { run: \"auto\", display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to import the functions that are required for the analysis.* \n",
        "# import all necesary packages\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "import scipy.ndimage as ndi\n",
        "from scipy.stats import ttest_ind_from_stats\n",
        "from skimage.filters.thresholding import threshold_otsu\n",
        "from skimage.measure import regionprops\n",
        "from scipy import signal\n",
        "from decimal import Decimal\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "from google.colab import files\n",
        "%matplotlib inline\n",
        "\n",
        "# define experiment class\n",
        "\n",
        "class experiment:\n",
        "  def __init__(self,path,time_res,pixel_res,nbleach,sigma):\n",
        "    self.file_name = path\n",
        "    self.img = imread(self.file_name)\n",
        "    self.nframes = np.shape(self.img)[0]\n",
        "    self.time_res,self.pixel_res,self.nbleach = time_res,pixel_res,(nbleach-1)\n",
        "    self.bleach_img = ndi.filters.gaussian_filter(self.img[self.nbleach,:,:],sigma)\n",
        "    self.prebleach_img = ndi.filters.gaussian_filter(self.img[(self.nbleach-1),:,:],sigma)\n",
        "  \n",
        "  def segment_cell(self,thr_nuc=0.1,nucsize_min=200,nucsize_max=20000000):\n",
        "    thresh = threshold_otsu(self.prebleach_img)*thr_nuc\n",
        "    self.nucmask = self.prebleach_img > thresh\n",
        "    self.nucmask = ndi.binary_fill_holes(self.nucmask)\n",
        "    self.nucmask = ndi.binary_closing(self.nucmask)\n",
        "    self.nucmask = ndi.label(self.nucmask)[0]\n",
        "    sizes = [(self.nucmask == x).sum() for x in np.unique(self.nucmask)[1:]]\n",
        "    for id,size in zip(np.unique(self.nucmask)[1:],sizes):\n",
        "      if size != np.max(sizes):\n",
        "        self.nucmask[self.nucmask==id] = 0\n",
        "    \n",
        "  def segment_condensate(self,use_nuc_mask=True,thr_cond=1.2,condsize_min=10,condsize_max=10000):\n",
        "    if use_nuc_mask==True:\n",
        "      self.prebleach_img[self.nucmask == 0] = 0 \n",
        "    thresh = threshold_otsu(self.prebleach_img)*thr_cond\n",
        "    self.condmask = self.prebleach_img > thresh\n",
        "    self.condmask = ndi.binary_fill_holes(self.condmask)\n",
        "    self.condmask = ndi.binary_closing(self.condmask)\n",
        "    self.condmask= ndi.label(self.condmask)[0]\n",
        "    sizes = [(self.condmask == x).sum() for x in np.unique(self.condmask)[1:]]\n",
        "    for id,size in zip(np.unique(self.nucmask)[1:],sizes):\n",
        "      if size>condsize_max or size<condsize_min:\n",
        "        self.condmask[self.condmask==id] = 0\n",
        "  \n",
        "  def getBleachedmask(self,alpha=0.75,sigma_b=2,beta=0.5,extra_pix=2):\n",
        "    # loop through the mask of condensates\n",
        "    self.bleachmask = np.zeros_like(self.condmask)\n",
        "    self.nonbleachmask = np.zeros_like(self.condmask)\n",
        "    for id in np.unique(self.condmask):\n",
        "        if np.mean(self.prebleach_img[self.condmask == id])*alpha >= np.mean(self.bleach_img[self.condmask == id]):\n",
        "          # determine x position of bleach boundary\n",
        "          temp_im = copy.deepcopy(self.prebleach_img)\n",
        "          temp_mask = copy.deepcopy(self.condmask)\n",
        "          temp_im[self.condmask != id] = 0\n",
        "          temp_mask[self.condmask != id] = 0\n",
        "          # get radius and eccentricity\n",
        "          self.radius = ((regionprops(temp_mask)[0].minor_axis_length+regionprops(temp_mask)[0].major_axis_length)/2)*self.pixel_res\n",
        "          self.eccentricity = regionprops(temp_mask)[0].eccentricity\n",
        "          self.nucmask[self.condmask == id] = 0\n",
        "          profile = np.mean(ndi.filters.gaussian_filter(temp_im,sigma=sigma_b),axis=0)\n",
        "          xmin = np.min(np.where(profile!=np.min(profile)))\n",
        "          xmax = np.max(np.where(profile!=np.min(profile)))\n",
        "          xmid = np.max(np.where(profile==max(profile)))\n",
        "          ymax = profile[np.max(np.where(profile==max(profile)))]\n",
        "          x_int = np.min(np.where(np.abs((ymax*beta)-profile[0:xmid])==np.min(np.abs((ymax*beta)-profile[0:xmid]))))\n",
        "          temp_bleach = copy.deepcopy(temp_im)\n",
        "          temp_nonbleach = copy.deepcopy(temp_im)\n",
        "\n",
        "          temp_bleach[:,(x_int-extra_pix):]  = 0\n",
        "          temp_nonbleach[:,:(x_int+extra_pix)]  = 0\n",
        "\n",
        "          self.bleachmask[temp_bleach!=0] = id\n",
        "          self.nonbleachmask[temp_nonbleach!=0] = id\n",
        "\n",
        "  def getIntensities(self):\n",
        "    self.time = np.arange(-(self.nbleach-1)*self.time_res,(self.nframes-self.nbleach+1)*self.time_res,self.time_res)\n",
        "    self.time_norm = self.time/(self.radius**2)\n",
        "    self.bleach_int = []\n",
        "    self.nonbleach_int = []\n",
        "    self.total_int = []\n",
        "    for i in range(self.nframes):\n",
        "      temp = self.img[i,:,:]\n",
        "      self.bleach_int.append(np.mean(temp[self.bleachmask!=0]))\n",
        "      self.nonbleach_int.append(np.mean(temp[self.nonbleachmask!=0]))\n",
        "      self.total_int.append(np.mean(temp[self.nucmask!=0]))\n",
        "  \n",
        "  def getNormalizedTraces(self,byTotal):\n",
        "    # normalize by external reference\n",
        "    if byTotal==True:\n",
        "      self.bleach_norm = np.array(self.bleach_int)/np.array(self.total_int)\n",
        "      self.nonbleach_norm = np.array(self.nonbleach_int)/np.array(self.total_int)\n",
        "    else:\n",
        "      self.bleach_norm = np.array(self.bleach_int)\n",
        "      self.nonbleach_norm = np.array(self.nonbleach_int)\n",
        "    # take into account the additional bleach in the non-bleached half\n",
        "    dif = self.nonbleach_norm[(self.nbleach-1)]-self.nonbleach_norm[self.nbleach]\n",
        "    self.nonbleach_norm1 = self.nonbleach_norm\n",
        "    self.bleach_norm1 = self.bleach_norm\n",
        "    self.nonbleach_norm1[self.nbleach:] = self.nonbleach_norm[self.nbleach:] + dif\n",
        "    self.nonbleach_norm1 = self.nonbleach_norm1-dif\n",
        "    self.bleach_norm1[self.nbleach:] = self.bleach_norm[self.nbleach:] + dif\n",
        "\n",
        "    # subtract non-bleached pool\n",
        "    self.bleach_norm2 = self.bleach_norm1 - self.bleach_norm1[self.nbleach]\n",
        "    self.nonbleach_norm2 = self.nonbleach_norm1 - self.nonbleach_norm1[(self.nbleach-1)]\n",
        "\n",
        "    # normalize both halves by their sizes\n",
        "    self.bleach_norm3 = self.bleach_norm2 * len(self.bleachmask[self.bleachmask!=0])\n",
        "    self.nonbleach_norm3 = self.nonbleach_norm2 * len(self.nonbleachmask[self.nonbleachmask!=0])\n",
        "\n",
        "    # normalize to unity\n",
        "    self.bleach_norm4 = self.bleach_norm3/(self.bleach_norm3[(self.nbleach-1)])#* len(self.bleachmask[self.bleachmask!=0]))\n",
        "    self.nonbleach_norm4 = self.nonbleach_norm3/(self.bleach_norm3[(self.nbleach-1)])#* len(self.nonbleachmask[self.nonbleachmask!=0]))\n",
        "    self.nonbleach_norm4 = self.nonbleach_norm4+1\n",
        "\n",
        "    # normalize by bound fraction\n",
        "    bound_fraction = np.mean(self.nonbleach_norm4[round(len(self.nonbleach_norm4)*0.9):])-np.mean(self.bleach_norm4[round(len(self.bleach_norm4)*0.9):])\n",
        "    self.bleach_normBF = self.bleach_norm4/(1-bound_fraction)\n",
        "    self.nonbleach_normBF = (self.nonbleach_norm4-1)/(1-bound_fraction)+1\n",
        "\n",
        "  def plotNormalizationProcess(self):\n",
        "    plt.rcParams['figure.figsize'] = [40, 5]\n",
        "    figure, axis = plt.subplots(1, 7)\n",
        "    axis[0].plot(self.time,self.bleach_int,color=\"green\")\n",
        "    axis[0].plot(self.time,self.nonbleach_int,color=\"violet\")\n",
        "    axis[0].set_xlabel(\"Time (s)\")\n",
        "    axis[0].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[0].set_title(\"Raw intensity\")\n",
        "\n",
        "    axis[1].plot(self.time,self.bleach_norm,color=\"green\")\n",
        "    axis[1].plot(self.time,self.nonbleach_norm,color=\"violet\")\n",
        "    axis[1].set_xlabel(\"Time (s)\")\n",
        "    axis[1].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[1].set_title(\"Normalized by total intensity\")\n",
        "\n",
        "    axis[2].plot(self.time,self.bleach_norm1,color=\"green\")\n",
        "    axis[2].plot(self.time,self.nonbleach_norm1,color=\"violet\")\n",
        "    axis[2].set_xlabel(\"Time (s)\")\n",
        "    axis[2].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[2].set_title(\"Bleaching in non-bleached half removed\")\n",
        "\n",
        "    axis[3].plot(self.time,self.bleach_norm2,color=\"green\")\n",
        "    axis[3].plot(self.time,self.nonbleach_norm2,color=\"violet\")\n",
        "    axis[3].set_xlabel(\"Time (s)\")\n",
        "    axis[3].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[3].set_title(\"First post-bleach frame subtracted\")\n",
        "\n",
        "    axis[4].plot(self.time,self.bleach_norm3,color=\"green\")\n",
        "    axis[4].plot(self.time,self.nonbleach_norm3,color=\"violet\")\n",
        "    axis[4].set_xlabel(\"Time (s)\")\n",
        "    axis[4].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[4].set_title(\"Normalized by size of bleached area\")\n",
        "\n",
        "    axis[5].plot(self.time,self.bleach_norm4,color=\"green\")\n",
        "    axis[5].plot(self.time,self.nonbleach_norm4,color=\"violet\")\n",
        "    axis[5].set_xlabel(\"Time (s)\")\n",
        "    axis[5].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[5].set_title(\"Double-normalized curves\")\n",
        "\n",
        "    axis[6].plot(self.time,self.bleach_normBF,color=\"green\")\n",
        "    axis[6].plot(self.time,self.nonbleach_normBF,color=\"violet\")\n",
        "    axis[6].set_xlabel(\"Time (s)\")\n",
        "    axis[6].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[6].set_title(\"Bound (immobile) fraction corrected\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def saveData(self,name):\n",
        "    tosave = np.array([self.time,self.time_norm,self.bleach_norm4,self.nonbleach_norm4,self.bleach_normBF,self.nonbleach_normBF]).T\n",
        "    np.savetxt(\"%s.csv\"%name, tosave, delimiter=',', header=\"Time,Time norm,Bleach,Non-Bleach,Bleach_BFnorm,Non-Bleach_BFnorm\", comments=\"# file = %s,droplet size = %s,droplet eccentricity = %s \\n\"%(self.file_name,self.radius,self.eccentricity))\n",
        "    \n",
        "\n",
        "class MOCHAdataset:\n",
        "  def __init__(self,folder_path):\n",
        "    self.folder = folder_path\n",
        "    # get all files\n",
        "    all_files = os.listdir(self.folder) \n",
        "    csv_files = list(filter(lambda f: f.endswith('.csv'), all_files))\n",
        "    # loop over all files and retrieve the data\n",
        "    self.file_name = []\n",
        "    self.droplet_size = []\n",
        "    self.droplet_eccentricity = []\n",
        "    self.time = []\n",
        "    self.time_norm = []\n",
        "    self.Bleach = []\n",
        "    self.Non_Bleach = []\n",
        "    self.Bleach_BFnorm = []\n",
        "    self.Non_Bleach_BFnorm = []\n",
        "    for file in csv_files:\n",
        "      with open(file) as f:\n",
        "        lines = f.readlines()\n",
        "        self.file_name.append(lines[0].split(\",\")[0].split(\" = \")[1])\n",
        "        self.droplet_size.append(float(lines[0].split(\",\")[1].split(\" = \")[1]))\n",
        "        self.droplet_eccentricity.append(float(lines[0].split(\",\")[2].split(\" = \")[1]))\n",
        "        time = []\n",
        "        time_norm = []\n",
        "        Bleach = []\n",
        "        Non_Bleach = []\n",
        "        Bleach_BFnorm = []\n",
        "        Non_Bleach_BFnorm = []\n",
        "\n",
        "        for line in lines[2:]:\n",
        "          time.append(float(line.split(\",\")[0]))\n",
        "          time_norm.append(float(line.split(\",\")[1]))\n",
        "          Bleach.append(float(line.split(\",\")[2]))\n",
        "          Non_Bleach.append(float(line.split(\",\")[3]))\n",
        "          Bleach_BFnorm.append(float(line.split(\",\")[4]))\n",
        "          Non_Bleach_BFnorm.append(float(line.split(\",\")[5]))\n",
        "\n",
        "        self.time.append(np.array(time))\n",
        "        self.time_norm.append(np.array(time_norm))\n",
        "        self.Bleach.append(np.array(Bleach))\n",
        "        self.Non_Bleach.append(np.array(Non_Bleach))\n",
        "        self.Bleach_BFnorm.append(np.array(Bleach_BFnorm))\n",
        "        self.Non_Bleach_BFnorm.append(np.array(Non_Bleach_BFnorm))\n",
        "    self.time = np.array(self.time)\n",
        "    self.time_norm = np.array(self.time_norm)\n",
        "    self.Bleach = np.array(self.Bleach)\n",
        "    self.Non_Bleach = np.array(self.Non_Bleach)\n",
        "    self.Bleach_BFnorm = np.array(self.Bleach_BFnorm)\n",
        "    self.Non_Bleach_BFnorm = np.array(self.Non_Bleach_BFnorm)\n",
        "    self.N = len(self.time)\n",
        "\n",
        "  def explore_data(self):\n",
        "    # get limits\n",
        "\n",
        "    x_norm_max = max([max(x) for x in self.time_norm])\n",
        "    x_max = max([max(x) for x in self.time])\n",
        "\n",
        "    # make plots\n",
        "    fig,axs = plt.subplots(nrows=2, ncols=3,figsize=(16, 8))\n",
        "\n",
        "    axs[0,0].plot(self.time[0],self.Non_Bleach[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[0,0].plot(self.time[i],self.Non_Bleach[i])\n",
        "    axs[0,0].set_xlabel(\"Time (s)\")\n",
        "    axs[0,0].set_ylabel(\"Non bleached Intensity\")\n",
        "    \n",
        "    \n",
        "    axs[1,0].plot(self.time[0],self.Bleach[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[1,0].plot(self.time[i],self.Bleach[i])\n",
        "    axs[1,0].set_xlabel(\"Time (s)\")\n",
        "    axs[1,0].set_ylabel(\"Bleached Intensity\")    \n",
        "    \n",
        "    axs[0,1].plot(self.time_norm[0],self.Non_Bleach[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[0,1].plot(self.time_norm[i],self.Non_Bleach[i])\n",
        "    axs[0,1].set_xlabel(\"Normalized time (s/µm2)\")\n",
        "    axs[0,1].set_ylabel(\"Non bleached Intensity\")\n",
        "   \n",
        "    \n",
        "    axs[1,1].plot(self.time_norm[0],self.Bleach[0], label=self.file_name[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[1,1].plot(self.time_norm[i],self.Bleach[i], label=self.file_name[i])\n",
        "    axs[1,1].set_xlabel(\"Normalized time (s/µm2)\")\n",
        "    axs[1,1].set_ylabel(\"Bleached Intensity\")\n",
        "\n",
        "    axs[1,1].legend(loc='lower center', bbox_to_anchor=(-1, -1, 2,-0.1), fancybox=True, mode=\"expand\", shadow=False, ncol=len(self.file_name)/4)    \n",
        "    \n",
        "\n",
        "    axs[0,2].plot(self.time[0],self.Non_Bleach_BFnorm[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[0,2].plot(self.time[i],self.Non_Bleach_BFnorm[i])\n",
        "    axs[0,2].set_xlabel(\"Time (s)\")\n",
        "    axs[0,2].set_ylabel(\"Non bleached, bound fraction corrected\")    \n",
        "    \n",
        "    axs[1,2].plot(self.time[0],self.Bleach_BFnorm[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[1,2].plot(self.time[i],self.Bleach_BFnorm[i])\n",
        "    axs[1,2].set_xlabel(\"Time (s)\")\n",
        "    axs[1,2].set_ylabel(\"Bleached, bound fraction corrected\")\n",
        "\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "      \n",
        "\n",
        "  def getAverage(self, use_norm_time = False, bound_fraction=False):\n",
        "    if use_norm_time == True:\n",
        "      minim_t = [min(x) for x in self.time_norm]\n",
        "      maxim_t = [max(x) for x in self.time_norm]\n",
        "      lens_t = [len(x) for x in self.time_norm]\n",
        "      self.new_time = np.arange(min(minim_t),max(maxim_t),(max(maxim_t)-min(minim_t))/min(lens_t))\n",
        "    else : \n",
        "      minim_t = [min(x) for x in self.time]\n",
        "      maxim_t = [max(x) for x in self.time]\n",
        "      lens_t = [len(x) for x in self.time]\n",
        "      self.new_time = np.arange(min(minim_t),max(maxim_t),(max(maxim_t)-min(minim_t))/min(lens_t))\n",
        "\n",
        "    if bound_fraction==False:\n",
        "      self.bleach_timecor = np.array([np.interp(x=self.new_time, xp=self.time_norm[i], fp=self.Bleach[i]) for i in range(len(self.Bleach))])\n",
        "      self.nonbleach_timecor = np.array([np.interp(x=self.new_time, xp=self.time_norm[i], fp=self.Non_Bleach[i]) for i in range(len(self.Non_Bleach))])\n",
        "    else:\n",
        "      self.bleach_timecor = np.array([np.interp(x=self.new_time, xp=self.time_norm[i], fp=self.Bleach_BFnorm[i]) for i in range(len(self.Bleach_BFnorm))])\n",
        "      self.nonbleach_timecor = np.array([np.interp(x=self.new_time, xp=self.time_norm[i], fp=self.Non_Bleach_BFnorm[i]) for i in range(len(self.Non_Bleach_BFnorm))])\n",
        "    \n",
        "    self.new_time = self.new_time*(np.mean(self.droplet_size)**2)\n",
        "    self.bleach_av = np.mean(self.bleach_timecor,axis=0)\n",
        "    self.nonbleach_av = np.mean(self.nonbleach_timecor,axis=0)\n",
        "    self.bleach_std = np.std(self.bleach_timecor,axis=0)\n",
        "    self.nonbleach_std = np.std(self.nonbleach_timecor,axis=0)\n",
        "    self.bleach_sem = np.std(self.bleach_timecor,axis=0)/ np.sqrt(np.size(self.bleach_timecor))\n",
        "    self.nonbleach_sem = np.std(self.nonbleach_timecor,axis=0)/ np.sqrt(np.size(self.bleach_timecor))\n",
        "\n",
        "\n",
        "  def makeNicePlot(self,std=True,sg_window=21,poly_order = 2):\n",
        "    # smooth the data and determine dip\n",
        "    data_smooth = signal.savgol_filter(self.nonbleach_av, window_length=sg_window, polyorder=poly_order, mode=\"nearest\")\n",
        "    self.dip = 1-min(data_smooth)\n",
        "    self.dip_er = float(self.nonbleach_std[np.isclose(((self.nonbleach_av - self.dip)**2),min((self.nonbleach_av - self.dip)**2))])\n",
        "    \n",
        "    # run Student's t-test\n",
        "    solution_dip = 0.1\n",
        "    solution_std = 0.0283\n",
        "    solution_n = 7\n",
        "    self.tstat, self.pvalue = ttest_ind_from_stats(self.dip, self.dip_er, self.N, solution_dip, solution_std, solution_n,equal_var=False,alternative=\"greater\")\n",
        "\n",
        "    # set up the axes with gridspec\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    grid = plt.GridSpec(2, 3, hspace=0.3, wspace=0.5)\n",
        "    hist_size = fig.add_subplot(grid[0,0])\n",
        "    hist_ecce = fig.add_subplot(grid[1,0])\n",
        "    main_ax = fig.add_subplot(grid[:,1:])\n",
        "    \n",
        "    # set error to be used\n",
        "    if std==True:\n",
        "      err1 = self.bleach_std\n",
        "      err2 = self.nonbleach_std\n",
        "    else:\n",
        "      err1 = self.bleach_sem\n",
        "      err2 = self.nonbleach_sem\n",
        "\n",
        "    main_ax.plot(self.new_time, self.bleach_av, color=\"darkgreen\")\n",
        "    main_ax.fill_between(self.new_time, self.bleach_av-err1, self.bleach_av+err1, color=\"limegreen\",alpha=0.4)\n",
        "    main_ax.plot(self.new_time, self.nonbleach_av, color=\"darkmagenta\")\n",
        "    main_ax.plot(self.new_time, data_smooth, color=\"black\",linestyle = '--')\n",
        "    main_ax.fill_between(self.new_time, self.nonbleach_av-err2, self.nonbleach_av+err2, color=\"magenta\",alpha=0.4)\n",
        "    main_ax.axhline(y = 0.9, color = 'grey', linestyle = '--')\n",
        "    main_ax.text((max(self.new_time)*0.7),0.1,\"Dip = %s\"%(f\"{self.dip:.2f}\"),fontsize=22)\n",
        "    main_ax.text((max(self.new_time)*0.7),0.025,\"p-value = %.2E\"%(Decimal(self.pvalue)),fontsize=16) \n",
        "    main_ax.set_xlabel(\"Time (s)\",fontsize=18) \n",
        "    main_ax.set_xlim(left=0)\n",
        "    main_ax.set_ylabel(\"Normalized intensity\",fontsize=18)\n",
        "\n",
        "    hist_size.boxplot(self.droplet_size)\n",
        "    hist_size.scatter([1 for x in range(len(self.droplet_size))], self.droplet_size)\n",
        "    hist_size.set_ylabel(\"Condensate size (µm)\",fontsize=18)\n",
        "    # hist_size.set_ylabel(\"Count\",fontsize=18)\n",
        "\n",
        "    hist_ecce.boxplot(self.droplet_eccentricity)\n",
        "    hist_ecce.scatter([1 for x in range(len(self.droplet_eccentricity))], self.droplet_eccentricity)\n",
        "    hist_ecce.set_ylabel(\"Eccentricity (a.u.)\",fontsize=18)\n",
        "    # hist_ecce.set_ylabel(\"Count\",fontsize=18)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def getEnergy(self):\n",
        "    coef_b = 0.1182024\n",
        "    coef_n = 2.12426\n",
        "    coef_a = 0.02712834\n",
        "    FirstTerm=(((0.5-coef_b)/(self.dip-0.5))-1)\n",
        "    #FirstTerm=float(f'{FirstTerm:.6f}')\n",
        "    SecondTerm=(1/coef_n)\n",
        "    #SecondTerm=float(f'{SecondTerm:.6f}')\n",
        "    self.EnergyBarrier= (FirstTerm**SecondTerm)*coef_a \n",
        "\n",
        "# helper functions\n",
        "\n",
        "def plot_mask(raw,mask,mask2=None,mask3=None):\n",
        "  # create edges array\n",
        "  #a = regionprops(mask)\n",
        "\n",
        "  edges1 = np.zeros_like(mask)\n",
        "  edges1 = np.ma.masked_where(edges1 == 0, edges1)\n",
        "  for ID in np.unique(mask)[1:]:\n",
        "    cell_mask = mask==ID\n",
        "    eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1)\n",
        "    edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
        "    edges1[edge_mask] = ID\n",
        "  try:\n",
        "    edges2 = np.zeros_like(mask2)\n",
        "    edges2 = np.ma.masked_where(edges2 == 0, edges2)\n",
        "    for ID in np.unique(mask2)[1:]:\n",
        "      cell_mask = mask2==ID\n",
        "      eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1)\n",
        "      edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
        "      edges2[edge_mask] = ID\n",
        "    edges2 = np.ma.masked_where(edges2 == 0, edges2)\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    edges3 = np.zeros_like(mask3)\n",
        "    edges3 = np.ma.masked_where(edges3 == 0, edges3)\n",
        "    for ID in np.unique(mask3)[1:]:\n",
        "      cell_mask = mask3==ID\n",
        "      eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1)\n",
        "      edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
        "      edges3[edge_mask] = ID\n",
        "    edges3 = np.ma.masked_where(edges3 == 0, edges3)\n",
        "  except:\n",
        "    pass\n",
        "  #plot\n",
        "\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.imshow(raw, interpolation='none', cmap='gray')\n",
        "  plt.imshow(edges1,interpolation='none',cmap='Reds_r',alpha=1)\n",
        "  try:\n",
        "      plt.imshow(edges2,interpolation='none',cmap='Greens_r',alpha=1)\n",
        "  except:\n",
        "        pass\n",
        "  try:\n",
        "      plt.imshow(edges3,interpolation='none',cmap='Blues_r',alpha=1)\n",
        "  except:\n",
        "    pass\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3fDcRUy-L9s"
      },
      "outputs": [],
      "source": [
        "#@title Load data { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to load a tiff stack containing the half-FRAP experiment. Make sure that it has **only one color channel, that only one structure of interest has been bleached, and that the bleached half is located on the left**.*\n",
        "load_data=False #@param {type:\"boolean\"}\n",
        "example=True #@param {type:\"boolean\"}\n",
        "#@markdown  - by checking the \"example\" box, an example of a half-FRAP experiment will be loaded\n",
        "if example == True:\n",
        "  !git clone https://github.com/dymochro/MOCHA_example.git\n",
        "elif load_data == True:\n",
        "  uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5oumc5n_Y11"
      },
      "outputs": [],
      "source": [
        "#@title Specify parameters { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to confirm the parameters below that are used for the analysis:*\n",
        "time_resolution = 0.03 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the time resolution of the experiment (in seconds per frame)\n",
        "pixel_size = 0.04 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the size (in µm) of each pixel\n",
        "bleach_frame = 4 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the number of the first post-bleach frame\n",
        "sigma = 1.15 #@param {type:\"raw\"}\n",
        "#@markdown  - Pre-processing: Specify the sigma value for the Gaussian blur filter used for segmentation\n",
        "if load_data==True: \n",
        "  paths = [x for x in os.listdir('.') if x.endswith('.tif')]\n",
        "  img_path = paths[0]\n",
        "elif example==True:\n",
        "  img_path = \"MOCHA_example/Mocha_Example.tif\"\n",
        "  # img_path = \"Example_MF/example1.tif\"\n",
        "  # img_path = \"Example_MF/example2.tif\"\n",
        "\n",
        "exp=experiment(img_path,time_resolution,pixel_size,nbleach=bleach_frame,sigma=sigma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH7one4IUt7H"
      },
      "outputs": [],
      "source": [
        "#@title Segment the cell (or the nucleus) { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to segment the entire cell (or nucleus) that is used as a reference for acquisition photobleaching.*\n",
        "#@markdown **When analyzing *in vitro* data, set the threshold as low as possible to segment the full image**\n",
        "intensity_threshold = 0.025 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a threshold for segmentation (a larger value corresponds to a more stringent segmentation)\n",
        "exp.segment_cell(thr_nuc=intensity_threshold)\n",
        "plot_mask(exp.bleach_img,exp.nucmask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KNMTfuYZRD-w"
      },
      "outputs": [],
      "source": [
        "#@title Segment the half-bleached structure of interest\n",
        "#@markdown *Click on the arrow to segment the structure of interest and to select the bleached one. **First specify the following parameters:** .*\n",
        "intensity_threshold = 1 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a scaling scaling factor to determine the intensity threshold for nuclear segmentation (a larger value corresponds to a more stringent segmentation)\n",
        "bleach_threshold = 0.9 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a scaling factor to segment the bleached structure of interest\n",
        "bleach_depth = 0.9 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a scaling factor to separate the bleached from the non-bleached half\n",
        "extra_pixels = 2 #@param {type:\"raw\"}\n",
        "#@markdown - specify the number of pixels between the bleached and the non-bleached half that are not considered for the analysis\n",
        "exp.segment_condensate(thr_cond=intensity_threshold)\n",
        "exp.getBleachedmask(alpha=bleach_threshold,sigma_b=1,beta=0.995,extra_pix=3)\n",
        "plot_mask(exp.bleach_img,exp.nucmask,exp.bleachmask,exp.nonbleachmask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QNfBPqjWAgZ"
      },
      "outputs": [],
      "source": [
        "#@title Calculate normalized half-FRAP curves { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to retrieve the raw intensities in both halves and to perform the corresponding normalization*\n",
        "Normalize_by_total_intensity=True #@param {type:\"boolean\"}\n",
        "#@markdown  - Specify if total intensity will be used for normalization\n",
        "exp.getIntensities()\n",
        "exp.getNormalizedTraces(byTotal=Normalize_by_total_intensity)\n",
        "exp.plotNormalizationProcess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTJfHq-3JnnV"
      },
      "outputs": [],
      "source": [
        "#@title Save normalized half-FRAP curves { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to confirm the name of the .csv file that will be downloaded to your computer.*\n",
        "name = \"example_2\" #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the name of the data set\n",
        "exp.saveData(name)\n",
        "files.download(\"%s.csv\"%name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JicQPoBp2sG"
      },
      "outputs": [],
      "source": [
        "#@title Remove data to continue the analysis { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to delete the current data set before uploading/analyzing the next one*\n",
        "!rm -r *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPy5e1kvlXdW"
      },
      "source": [
        "## **Part II: Analysis of dataset with normalized curves**\n",
        "*After having analyzed the individual experiments using the code above, use the steps below to upload the respective csv files (containing analyzed replicates for the same condition) to average them, determine the dip depth, and test if molecules undergo LLPS or ICBS*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVaB44IUj2GZ"
      },
      "outputs": [],
      "source": [
        "#@title Load .csv files containing individual replicates { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to select all the .csv files that contain replicates analyzed according to the steps indicated above*\n",
        "uploaded = files.upload()\n",
        "# check all files with .csv extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CREv6HxmdxD"
      },
      "outputs": [],
      "source": [
        "#@title Run analysis with the options below { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to run the analysis with the options below*\n",
        "bound_fraction = False #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if the curves should be normalized by the bound (immobile) fraction\n",
        "use_std = True #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if the standard deviation (true) or the standard error of the mean (false) should be plotted\n",
        "filter_window = 21 #@param {type:\"raw\"}\n",
        "#@markdown - Specify the window length for the Savitzky-Golay filter that is used to smooth the curve for the non-bleached half \n",
        "order_polynomial = 2 #@param {type:\"raw\"}\n",
        "#@markdown - Specify the polynomial order for the Savitzky-Golay filter that is used to smooth the curve for the non-bleached half \n",
        "\n",
        "path = os.getcwd()\n",
        "alldata=MOCHAdataset(path)    \n",
        "alldata.getAverage(bound_fraction=bound_fraction)\n",
        "alldata.makeNicePlot(std=use_std,sg_window=filter_window,poly_order = order_polynomial)\n",
        "alldata.getEnergy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wQgjcWgtG4n"
      },
      "outputs": [],
      "source": [
        "#@title Interpret the result { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to interpret the result*\n",
        "print(\"FINAL REPORT:\")\n",
        "if alldata.pvalue <= 0.01:\n",
        "  print(\"The dip depth of the sample was significantly higher than the dip depth expected for freely diffusing molecules (p<0.01)\")\n",
        "  print(\"This indicates that the molecules of interest feel a barrier at the interface of the structure of interest, which is a hallmark of LLPS.\")\n",
        "  print(\"By using the calibration curve from Muzzopappa et al. 2022, the energy barrier determined from the dip depth is %s kT\"%alldata.EnergyBarrier)\n",
        "else:\n",
        "  print(\"The dip depth (%s) is not significantly larger than the dip depth seen for freely diffusing molecules.\"%alldata.dip)\n",
        "  print(\"This indicates that the molecules of interest do not feel any barrier at the interface of the structure of interest, indicating that molecules undergo ICBS.\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
