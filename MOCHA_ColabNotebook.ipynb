{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dymochro/MOCHA/blob/main/MOCHA_ColabNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsg-rAgwpeSC"
      },
      "source": [
        "# MOCHA-FRAP\n",
        "MOCHA-FRAP is a quantitative half-FRAP approach to assess if molecules in a structure of interest undergo liquid-liquid phase separation (LLPS) driven by multivalent interactions, or if they undergo low-valency interactions with spatially clustered binding sites (ICBS) on an immobile scaffold. MOCHA-FRAP distinguishes both models by quantifying the apparent energy barrier at the interface of the structure of interest. The theoretical and experimental background can be found in <a href=\"https://www.nature.com/articles/s41467-022-35430-y\">Muzzopappa et al., 2022</a>.\n",
        "\n",
        "**Before performing half-FRAP experiments, check Supplementary Note 2 in <a href=\"https://www.nature.com/articles/s41467-022-35430-y\">Muzzopappa et al., 2022</a> for advice on how to perform experiments that are suitable for the workflow described here.**\n",
        "\n",
        "**This Colab Notebook is intended to provide a user-friendly interface to quantitatively analyze half-FRAP data. It consists of two parts:**\n",
        "- **Analysis of individual experiments:** *Allows you to segment the nucleus/cytoplasm and the bleached structure of interest in an image stack, to retrieve the raw intensity traces, and to perform the corresponding normalization. The results can then be downloaded as .csv file.*\n",
        "- **Analysis of dataset with normalized curves:** *Allows you to upload the .csv files generated in the previous step, to plot the average curve, to determine the dip depth in the non-bleached half, and to decide if the bleached protein undergoes LLPS or ICBS.*\n",
        "\n",
        "*Version: 3.075*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EymKmRzbpaCi"
      },
      "source": [
        "## **Part I: Analysis of individual experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HdUeJGI1SIt"
      },
      "outputs": [],
      "source": [
        "#@title Import functions { run: \"auto\", display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to import the functions that are required for the analysis.* \n",
        "# import all necesary packages\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "import scipy.ndimage as ndi\n",
        "from scipy.stats import ttest_ind_from_stats\n",
        "from skimage.filters.thresholding import threshold_otsu\n",
        "from skimage.measure import regionprops\n",
        "from skimage.filters import gaussian\n",
        "from skimage.registration import phase_cross_correlation as register_translation\n",
        "from scipy import signal\n",
        "from decimal import Decimal\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "from google.colab import files\n",
        "%matplotlib inline\n",
        "\n",
        "# define experiment class\n",
        "\n",
        "class experiment:\n",
        "  def __init__(self,path,time_res,pixel_res,nbleach,sigma):\n",
        "    self.file_name = path\n",
        "    self.nbleach = nbleach\n",
        "    self.img = imread(self.file_name)\n",
        "    self.nframes = np.shape(self.img)[0]\n",
        "    self.time_res,self.pixel_res,self.nbleach = time_res,pixel_res,(nbleach-1)\n",
        "    self.bleach_img = ndi.filters.gaussian_filter(self.img[self.nbleach,:,:],sigma)\n",
        "    self.prebleach_img = ndi.filters.gaussian_filter(self.img[(self.nbleach-1),:,:],sigma)\n",
        "  \n",
        "  def segment_cell(self,thr_nuc=0.1,nucsize_min=200,nucsize_max=20000000):\n",
        "    thresh = threshold_otsu(self.prebleach_img)*thr_nuc\n",
        "    self.nucmask = self.prebleach_img > thresh\n",
        "    self.nucmask = ndi.binary_fill_holes(self.nucmask)\n",
        "    self.nucmask = ndi.binary_closing(self.nucmask)\n",
        "    self.nucmask = ndi.label(self.nucmask)[0]\n",
        "    sizes = [(self.nucmask == x).sum() for x in np.unique(self.nucmask)[1:]]\n",
        "    for id,size in zip(np.unique(self.nucmask)[1:],sizes):\n",
        "      if size != np.max(sizes):\n",
        "        self.nucmask[self.nucmask==id] = 0\n",
        "    \n",
        "  def segment_condensate(self,use_nuc_mask=True,thr_cond=1.2,condsize_min=10,condsize_max=10000):\n",
        "    if use_nuc_mask==True:\n",
        "      self.prebleach_img[self.nucmask == 0] = 0 \n",
        "    thresh = threshold_otsu(self.prebleach_img)*thr_cond\n",
        "    self.condmask = self.prebleach_img > thresh\n",
        "    self.condmask = ndi.binary_fill_holes(self.condmask)\n",
        "    self.condmask = ndi.binary_closing(self.condmask)\n",
        "    self.condmask= ndi.label(self.condmask)[0]\n",
        "    sizes = [(self.condmask == x).sum() for x in np.unique(self.condmask)[1:]]\n",
        "    for id,size in zip(np.unique(self.condmask)[1:],sizes):\n",
        "      if size>condsize_max or size<condsize_min:\n",
        "        self.condmask[self.condmask==id] = 0\n",
        "  \n",
        "  def getBleachedmask(self,alpha=0.75,sigma_b=2,beta=0.5,extra_pix=2,shift_x=0):\n",
        "    # loop through the mask of condensates\n",
        "    self.bleachmask = np.zeros_like(self.condmask)\n",
        "    self.nonbleachmask = np.zeros_like(self.condmask)\n",
        "    for id in np.unique(self.condmask):\n",
        "        if np.mean(self.prebleach_img[self.condmask == id])*alpha >= np.mean(self.bleach_img[self.condmask == id]):\n",
        "          # determine x position of bleach boundary\n",
        "          temp_im = copy.deepcopy(self.prebleach_img)\n",
        "          temp_mask = copy.deepcopy(self.condmask)\n",
        "          temp_im[self.condmask != id] = 0\n",
        "          temp_mask[self.condmask != id] = 0\n",
        "          # get radius and eccentricity\n",
        "          self.radius = ((regionprops(temp_mask)[0].minor_axis_length+regionprops(temp_mask)[0].major_axis_length)/2)*self.pixel_res\n",
        "          self.eccentricity = regionprops(temp_mask)[0].eccentricity\n",
        "          self.nucmask[self.condmask == id] = 0\n",
        "          profile = np.mean(ndi.filters.gaussian_filter(temp_im,sigma=sigma_b),axis=0)\n",
        "          xmin = np.min(np.where(profile!=np.min(profile)))\n",
        "          xmax = np.max(np.where(profile!=np.min(profile)))\n",
        "          xmid = np.max(np.where(profile==max(profile)))\n",
        "          ymax = profile[np.max(np.where(profile==max(profile)))]\n",
        "          x_int = np.min(np.where(np.abs((ymax*beta)-profile[0:xmid])==np.min(np.abs((ymax*beta)-profile[0:xmid]))))\n",
        "          x_int =x_int+shift_x\n",
        "          temp_bleach = copy.deepcopy(temp_im)\n",
        "          temp_nonbleach = copy.deepcopy(temp_im)\n",
        "\n",
        "          temp_bleach[:,(x_int-extra_pix):]  = 0\n",
        "          temp_nonbleach[:,:(x_int+extra_pix)]  = 0\n",
        "\n",
        "          self.bleachmask[temp_bleach!=0] = id\n",
        "          self.nonbleachmask[temp_nonbleach!=0] = id\n",
        "\n",
        "  def track_masks(self,ext=5,ext2=25):\n",
        "    reg = register(self.img, self.nbleach, self.nonbleachmask,\n",
        "             extension=ext, extension2=ext2,blur=1)\n",
        "    print(reg)\n",
        "\n",
        "  def getIntensities(self):\n",
        "    self.time = np.arange(-(self.nbleach-1)*self.time_res,(self.nframes-self.nbleach+1)*self.time_res,self.time_res)\n",
        "    self.time_norm = self.time/(self.radius**2)\n",
        "    self.bleach_int = []\n",
        "    self.nonbleach_int = []\n",
        "    self.total_int = []\n",
        "    for i in range(self.nframes):\n",
        "      temp = self.img[i,:,:]\n",
        "      self.bleach_int.append(np.mean(temp[self.bleachmask!=0]))\n",
        "      self.nonbleach_int.append(np.mean(temp[self.nonbleachmask!=0]))\n",
        "      self.total_int.append(np.mean(temp[self.nucmask!=0]))\n",
        "  \n",
        "  def getNormalizedTraces(self,byTotal):\n",
        "    # normalize by external reference\n",
        "    if byTotal==True:\n",
        "      self.bleach_norm = np.array(self.bleach_int)/np.array(self.total_int)\n",
        "      self.nonbleach_norm = np.array(self.nonbleach_int)/np.array(self.total_int)\n",
        "    else:\n",
        "      self.bleach_norm = np.array(self.bleach_int)\n",
        "      self.nonbleach_norm = np.array(self.nonbleach_int)\n",
        "    # take into account the additional bleach in the non-bleached half\n",
        "    dif = self.nonbleach_norm[(self.nbleach-1)]-self.nonbleach_norm[self.nbleach]\n",
        "    self.nonbleach_norm1 = self.nonbleach_norm\n",
        "    self.bleach_norm1 = self.bleach_norm\n",
        "    self.nonbleach_norm1[self.nbleach:] = self.nonbleach_norm[self.nbleach:] + dif\n",
        "    self.nonbleach_norm1 = self.nonbleach_norm1-dif\n",
        "    self.bleach_norm1[self.nbleach:] = self.bleach_norm[self.nbleach:] + dif\n",
        "\n",
        "    # subtract non-bleached pool\n",
        "    self.bleach_norm2 = self.bleach_norm1 - self.bleach_norm1[self.nbleach]\n",
        "    self.nonbleach_norm2 = self.nonbleach_norm1 - self.nonbleach_norm1[(self.nbleach-1)]\n",
        "\n",
        "    # normalize both halves by their sizes\n",
        "    self.bleach_norm3 = self.bleach_norm2 * len(self.bleachmask[self.bleachmask!=0])\n",
        "    self.nonbleach_norm3 = self.nonbleach_norm2 * len(self.nonbleachmask[self.nonbleachmask!=0])\n",
        "\n",
        "    # normalize to unity\n",
        "    self.bleach_norm4 = self.bleach_norm3/(self.bleach_norm3[(self.nbleach-1)])#* len(self.bleachmask[self.bleachmask!=0]))\n",
        "    self.nonbleach_norm4 = self.nonbleach_norm3/(self.bleach_norm3[(self.nbleach-1)])#* len(self.nonbleachmask[self.nonbleachmask!=0]))\n",
        "    self.nonbleach_norm4 = self.nonbleach_norm4+1\n",
        "\n",
        "    # normalize by bound fraction\n",
        "    bound_fraction = np.mean(self.nonbleach_norm4[round(len(self.nonbleach_norm4)*0.9):])-np.mean(self.bleach_norm4[round(len(self.bleach_norm4)*0.9):])\n",
        "    self.bleach_normBF = self.bleach_norm4/(1-bound_fraction)\n",
        "    self.nonbleach_normBF = (self.nonbleach_norm4-1)/(1-bound_fraction)+1\n",
        "\n",
        "  def plotNormalizationProcess(self):\n",
        "    plt.rcParams['figure.figsize'] = [40, 5]\n",
        "    figure, axis = plt.subplots(1, 7)\n",
        "    axis[0].plot(self.time,self.bleach_int,color=\"green\")\n",
        "    axis[0].plot(self.time,self.nonbleach_int,color=\"violet\")\n",
        "    axis[0].set_xlabel(\"Time (s)\")\n",
        "    axis[0].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[0].set_title(\"Raw intensity\")\n",
        "\n",
        "    axis[1].plot(self.time,self.bleach_norm,color=\"green\")\n",
        "    axis[1].plot(self.time,self.nonbleach_norm,color=\"violet\")\n",
        "    axis[1].set_xlabel(\"Time (s)\")\n",
        "    axis[1].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[1].set_title(\"Normalized by total intensity\")\n",
        "\n",
        "    axis[2].plot(self.time,self.bleach_norm1,color=\"green\")\n",
        "    axis[2].plot(self.time,self.nonbleach_norm1,color=\"violet\")\n",
        "    axis[2].set_xlabel(\"Time (s)\")\n",
        "    axis[2].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[2].set_title(\"Bleaching in non-bleached half removed\")\n",
        "\n",
        "    axis[3].plot(self.time,self.bleach_norm2,color=\"green\")\n",
        "    axis[3].plot(self.time,self.nonbleach_norm2,color=\"violet\")\n",
        "    axis[3].set_xlabel(\"Time (s)\")\n",
        "    axis[3].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[3].set_title(\"First post-bleach frame subtracted\")\n",
        "\n",
        "    axis[4].plot(self.time,self.bleach_norm3,color=\"green\")\n",
        "    axis[4].plot(self.time,self.nonbleach_norm3,color=\"violet\")\n",
        "    axis[4].set_xlabel(\"Time (s)\")\n",
        "    axis[4].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[4].set_title(\"Normalized by size of bleached area\")\n",
        "\n",
        "    axis[5].plot(self.time,self.bleach_norm4,color=\"green\")\n",
        "    axis[5].plot(self.time,self.nonbleach_norm4,color=\"violet\")\n",
        "    axis[5].set_xlabel(\"Time (s)\")\n",
        "    axis[5].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[5].set_title(\"Double-normalized curves\")\n",
        "\n",
        "    axis[6].plot(self.time,self.bleach_normBF,color=\"green\")\n",
        "    axis[6].plot(self.time,self.nonbleach_normBF,color=\"violet\")\n",
        "    axis[6].set_xlabel(\"Time (s)\")\n",
        "    axis[6].set_ylabel(\"Fluorescence intensity\")\n",
        "    axis[6].set_title(\"Bound (immobile) fraction corrected\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def saveData(self,name):\n",
        "    tosave = np.array([self.time,self.time_norm,self.bleach_norm4,self.nonbleach_norm4,self.bleach_normBF,self.nonbleach_normBF]).T\n",
        "    np.savetxt(\"%s.csv\"%name, tosave, delimiter=',', header=\"Time,Time norm,Bleach,Non-Bleach,Bleach_BFnorm,Non-Bleach_BFnorm\", comments=\"# file = %s,droplet size = %s,droplet eccentricity = %s \\n\"%(self.file_name,self.radius,self.eccentricity))\n",
        "    \n",
        "\n",
        "class MOCHAdataset:\n",
        "  def __init__(self,folder_path):\n",
        "    self.folder = folder_path\n",
        "    # get all files\n",
        "    all_files = os.listdir(self.folder) \n",
        "    csv_files = list(filter(lambda f: f.endswith('.csv'), all_files))\n",
        "    # loop over all files and retrieve the data\n",
        "    self.file_name = []\n",
        "    self.droplet_size = []\n",
        "    self.droplet_eccentricity = []\n",
        "    self.time = []\n",
        "    self.time_norm = []\n",
        "    self.Bleach = []\n",
        "    self.Non_Bleach = []\n",
        "    self.Bleach_BFnorm = []\n",
        "    self.Non_Bleach_BFnorm = []\n",
        "    for file in csv_files:\n",
        "      with open(file) as f:\n",
        "        lines = f.readlines()\n",
        "        self.file_name.append(lines[0].split(\",\")[0].split(\" = \")[1])\n",
        "        self.droplet_size.append(float(lines[0].split(\",\")[1].split(\" = \")[1]))\n",
        "        self.droplet_eccentricity.append(float(lines[0].split(\",\")[2].split(\" = \")[1]))\n",
        "        time = []\n",
        "        time_norm = []\n",
        "        Bleach = []\n",
        "        Non_Bleach = []\n",
        "        Bleach_BFnorm = []\n",
        "        Non_Bleach_BFnorm = []\n",
        "\n",
        "        for line in lines[2:]:\n",
        "          time.append(float(line.split(\",\")[0]))\n",
        "          time_norm.append(float(line.split(\",\")[1]))\n",
        "          Bleach.append(float(line.split(\",\")[2]))\n",
        "          Non_Bleach.append(float(line.split(\",\")[3]))\n",
        "          Bleach_BFnorm.append(float(line.split(\",\")[4]))\n",
        "          Non_Bleach_BFnorm.append(float(line.split(\",\")[5]))\n",
        "\n",
        "        self.time.append(np.array(time))\n",
        "        self.time_norm.append(np.array(time_norm))\n",
        "        self.Bleach.append(np.array(Bleach))\n",
        "        self.Non_Bleach.append(np.array(Non_Bleach))\n",
        "        self.Bleach_BFnorm.append(np.array(Bleach_BFnorm))\n",
        "        self.Non_Bleach_BFnorm.append(np.array(Non_Bleach_BFnorm))\n",
        "    self.time = np.array(self.time)\n",
        "    self.time_norm = np.array(self.time_norm)\n",
        "    self.Bleach = np.array(self.Bleach)\n",
        "    self.Non_Bleach = np.array(self.Non_Bleach)\n",
        "    self.Bleach_BFnorm = np.array(self.Bleach_BFnorm)\n",
        "    self.Non_Bleach_BFnorm = np.array(self.Non_Bleach_BFnorm)\n",
        "    self.N = len(self.time)\n",
        "\n",
        "  def explore_data(self):\n",
        "    # get limits\n",
        "\n",
        "    x_norm_max = max([max(x) for x in self.time_norm])\n",
        "    x_max = max([max(x) for x in self.time])\n",
        "\n",
        "    # make plots\n",
        "    fig,axs = plt.subplots(nrows=2, ncols=3,figsize=(16, 8))\n",
        "\n",
        "    axs[0,0].plot(self.time[0],self.Non_Bleach[0], linewidth=0.75)\n",
        "    for i in range(1,self.N):\n",
        "      axs[0,0].plot(self.time[i],self.Non_Bleach[i], linewidth=0.75)\n",
        "    axs[0,0].set_xlabel(\"Time (s)\")\n",
        "    axs[0,0].set_ylabel(\"Non bleached Intensity\")\n",
        "    \n",
        "    \n",
        "    axs[1,0].plot(self.time[0],self.Bleach[0], linewidth=0.75)\n",
        "    for i in range(1,self.N):\n",
        "      axs[1,0].plot(self.time[i],self.Bleach[i], linewidth=0.75)\n",
        "    axs[1,0].set_xlabel(\"Time (s)\")\n",
        "    axs[1,0].set_ylabel(\"Bleached Intensity\")    \n",
        "    \n",
        "    axs[0,1].plot(self.time_norm[0],self.Non_Bleach[0], linewidth=0.75)\n",
        "    for i in range(1,self.N):\n",
        "      axs[0,1].plot(self.time_norm[i],self.Non_Bleach[i], linewidth=0.75)\n",
        "    axs[0,1].set_xlabel(\"Normalized time (s/µm2)\")\n",
        "    axs[0,1].set_ylabel(\"Non bleached Intensity\")\n",
        "   \n",
        "    \n",
        "    axs[1,1].plot(self.time_norm[0],self.Bleach[0], linewidth=0.75, label=self.file_name[0])\n",
        "    for i in range(1,self.N):\n",
        "      axs[1,1].plot(self.time_norm[i],self.Bleach[i], linewidth=0.75, label=self.file_name[i])\n",
        "    axs[1,1].set_xlabel(\"Normalized time (s/µm2)\")\n",
        "    axs[1,1].set_ylabel(\"Bleached Intensity\")\n",
        "\n",
        "    axs[1,1].legend(loc='lower center', bbox_to_anchor=(-1.3, -0.75, 3.6,0.5), fancybox=True, mode=\"expand\", shadow=False, ncol=len(self.file_name)/4)    \n",
        "    \n",
        "\n",
        "    axs[0,2].plot(self.time[0],self.Non_Bleach_BFnorm[0], linewidth=0.75)\n",
        "    for i in range(1,self.N):\n",
        "      axs[0,2].plot(self.time[i],self.Non_Bleach_BFnorm[i], linewidth=0.75)\n",
        "    axs[0,2].set_xlabel(\"Time (s)\")\n",
        "    axs[0,2].set_ylabel(\"Non bleached, bound fraction corrected\")    \n",
        "    \n",
        "    axs[1,2].plot(self.time[0],self.Bleach_BFnorm[0], linewidth=0.75)\n",
        "    for i in range(1,self.N):\n",
        "      axs[1,2].plot(self.time[i],self.Bleach_BFnorm[i], linewidth=0.75)\n",
        "    axs[1,2].set_xlabel(\"Time (s)\")\n",
        "    axs[1,2].set_ylabel(\"Bleached, bound fraction corrected\")\n",
        "\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "      \n",
        "\n",
        "  def getAverage(self, use_norm_time = True, bound_fraction=False,selection_ecc=False,min_ecc=0,max_ecc=1,selection_size=False,min_size=0,max_size=2):\n",
        "    \n",
        "    if selection_ecc==True:\n",
        "      times = np.array([x for i,x in enumerate(self.time) if ((self.droplet_eccentricity[i]>min_ecc) & (self.droplet_eccentricity[i]<max_ecc))])\n",
        "      times_norm = np.array([x for i,x in enumerate(self.time_norm) if ((self.droplet_eccentricity[i]>min_ecc) & (self.droplet_eccentricity[i]<max_ecc))])\n",
        "      nb = np.array([x for i,x in enumerate(self.Non_Bleach) if ((self.droplet_eccentricity[i]>min_ecc) & (self.droplet_eccentricity[i]<max_ecc))])\n",
        "      b = np.array([x for i,x in enumerate(self.Bleach) if ((self.droplet_eccentricity[i]>min_ecc) & (self.droplet_eccentricity[i]<max_ecc))])\n",
        "      nb_bc = np.array([x for i,x in enumerate(self.Non_Bleach_BFnorm) if ((self.droplet_eccentricity[i]>min_ecc) & (self.droplet_eccentricity[i]<max_ecc))])\n",
        "      b_bc = np.array([x for i,x in enumerate(self.Bleach_BFnorm) if ((self.droplet_eccentricity[i]>min_ecc) & (self.droplet_eccentricity[i]<max_ecc))])\n",
        "    elif selection_size==True:\n",
        "      times = np.array([x for i,x in enumerate(self.time) if ((self.droplet_size[i]>min_size) & (self.droplet_size[i]<max_size))])\n",
        "      times_norm = np.array([x for i,x in enumerate(self.time_norm) if ((self.droplet_size[i]>min_size) & (self.droplet_size[i]<max_size))])\n",
        "      nb = np.array([x for i,x in enumerate(self.Non_Bleach) if ((self.droplet_size[i]>min_size) & (self.droplet_size[i]<max_size))])\n",
        "      b = np.array([x for i,x in enumerate(self.Bleach) if ((self.droplet_size[i]>min_size) & (self.droplet_size[i]<max_size))])\n",
        "      nb_bc = np.array([x for i,x in enumerate(self.Non_Bleach_BFnorm) if ((self.droplet_size[i]>min_size) & (self.droplet_size[i]<max_size))])\n",
        "      b_bc = np.array([x for i,x in enumerate(self.Bleach_BFnorm) if ((self.droplet_size[i]>min_size) & (self.droplet_size[i]<max_size))])\n",
        "    else:  \n",
        "      times = self.time\n",
        "      times_norm = self.time_norm\n",
        "      nb = self.Non_Bleach\n",
        "      b = self.Bleach\n",
        "      nb_bc = self.Non_Bleach_BFnorm\n",
        "      b_bc = self.Bleach_BFnorm\n",
        "\n",
        "    if use_norm_time == True:\n",
        "      minim_t = [min(x) for x in self.time_norm]\n",
        "      maxim_t = [max(x) for x in self.time_norm]\n",
        "      lens_t = [len(x) for x in self.time_norm]\n",
        "      self.new_time = np.arange(min(minim_t),max(maxim_t),(max(maxim_t)-min(minim_t))/min(lens_t))\n",
        "    else : \n",
        "      minim_t = [min(x) for x in times]\n",
        "      maxim_t = [max(x) for x in times]\n",
        "      lens_t = [len(x) for x in times]\n",
        "      self.new_time = np.arange(min(minim_t),max(maxim_t),(max(maxim_t)-min(minim_t))/min(lens_t))\n",
        "\n",
        "    if bound_fraction==False:\n",
        "      self.bleach_timecor = np.array([np.interp(x=self.new_time, xp=times_norm[i], fp=b[i]) for i in range(len(b))])\n",
        "      self.nonbleach_timecor = np.array([np.interp(x=self.new_time, xp=times_norm[i], fp=nb[i]) for i in range(len(nb))])\n",
        "    else:\n",
        "      self.bleach_timecor = np.array([np.interp(x=self.new_time, xp=times_norm[i], fp=b_bc[i]) for i in range(len(b_bc))])\n",
        "      self.nonbleach_timecor = np.array([np.interp(x=self.new_time, xp=times_norm[i], fp=nb_bc[i]) for i in range(len(nb_bc))])\n",
        "    \n",
        "    self.new_time = self.new_time*(np.mean(self.droplet_size)**2)\n",
        "    self.bleach_av = np.mean(self.bleach_timecor,axis=0)\n",
        "    self.nonbleach_av = np.mean(self.nonbleach_timecor,axis=0)\n",
        "    self.bleach_std = np.std(self.bleach_timecor,axis=0)\n",
        "    self.nonbleach_std = np.std(self.nonbleach_timecor,axis=0)\n",
        "    self.bleach_sem = np.std(self.bleach_timecor,axis=0)/ np.sqrt(np.size(self.bleach_timecor))\n",
        "    self.nonbleach_sem = np.std(self.nonbleach_timecor,axis=0)/ np.sqrt(np.size(self.bleach_timecor))\n",
        "\n",
        "\n",
        "  def makeNicePlot(self,std=True,sg_window=21,poly_order = 2,selection_ecc=False,min_ecc=0,max_ecc=1,selection_size=False,min_size=0,max_size=2):\n",
        "    selection = False\n",
        "    ecc = self.droplet_eccentricity \n",
        "    sizes = self.droplet_size \n",
        "    if selection_ecc==True:\n",
        "      ecc = [x for x in self.droplet_eccentricity if ((x<max_ecc) & (x>min_ecc))]\n",
        "      sizes = [x for i,x in enumerate(self.droplet_size) if ((self.droplet_eccentricity[i]<max_ecc) & (self.droplet_eccentricity[i]>min_ecc))]\n",
        "      new_N = len(ecc)\n",
        "      selection = True\n",
        "    if selection_size==True:\n",
        "      sizes = [x for x in self.droplet_size if ((x<max_size) & (x>min_size))]\n",
        "      ecc = [x for i,x in enumerate(self.droplet_eccentricity) if ((self.droplet_size[i]<max_size) & (self.droplet_size[i]>min_size))]\n",
        "      new_N = len(sizes)\n",
        "      selection = True\n",
        "\n",
        "\n",
        "    # smooth the data and determine dip\n",
        "    data_smooth = signal.savgol_filter(self.nonbleach_av, window_length=sg_window, polyorder=poly_order, mode=\"nearest\")\n",
        "    self.dip = 1-np.nanmin(data_smooth)\n",
        "    self.dip_er = float(self.nonbleach_std[np.isclose(((self.nonbleach_av - self.dip)**2),np.nanmin((self.nonbleach_av - self.dip)**2))])\n",
        "    \n",
        "    # run Student's t-test\n",
        "    solution_dip = 0.1\n",
        "    solution_std = 0.0283\n",
        "    solution_n = 7\n",
        "    self.tstat, self.pvalue = ttest_ind_from_stats(self.dip, self.dip_er, self.N, solution_dip, solution_std, solution_n,equal_var=False,alternative=\"greater\")\n",
        "\n",
        "    # set up the axes with gridspec\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    grid = plt.GridSpec(2, 3, hspace=0.3, wspace=0.5)\n",
        "    hist_size = fig.add_subplot(grid[0,0])\n",
        "    hist_ecce = fig.add_subplot(grid[1,0])\n",
        "    main_ax = fig.add_subplot(grid[:,1:])\n",
        "    \n",
        "    # set error to be used\n",
        "    if std==True:\n",
        "      err1 = self.bleach_std\n",
        "      err2 = self.nonbleach_std\n",
        "    else:\n",
        "      err1 = self.bleach_sem\n",
        "      err2 = self.nonbleach_sem\n",
        "\n",
        "    main_ax.scatter(self.new_time, self.bleach_av, color=\"darkgreen\")\n",
        "    main_ax.fill_between(self.new_time, self.bleach_av-err1, self.bleach_av+err1, color=\"limegreen\",alpha=0.4)\n",
        "    main_ax.scatter(self.new_time, self.nonbleach_av, color=\"darkmagenta\")\n",
        "    main_ax.plot(self.new_time, data_smooth, color=\"black\",linestyle = '--')\n",
        "    main_ax.fill_between(self.new_time, self.nonbleach_av-err2, self.nonbleach_av+err2, color=\"magenta\",alpha=0.4)\n",
        "    main_ax.axhline(y = 0.9, color = 'grey', linestyle = '--')\n",
        "    main_ax.text((max(self.new_time)*0.7),0.1,\"Dip = %s\"%(f\"{self.dip:.2f}\"),fontsize=22)\n",
        "    main_ax.text((max(self.new_time)*0.7),0.025,\"p-value = %.2E\"%(Decimal(self.pvalue)),fontsize=16)\n",
        "    if selection==False: \n",
        "      main_ax.text((max(self.new_time)*0.7),-0.025,\"N = %s\"%(len(self.time)),fontsize=14)\n",
        "    else:\n",
        "      main_ax.text((max(self.new_time)*0.7),-0.025,\"N = %s\"%(new_N),fontsize=14)\n",
        "    main_ax.set_xlabel(\"Time (s)\",fontsize=18) \n",
        "    main_ax.set_xlim(left=0)\n",
        "    main_ax.set_ylim(-0.05,1.2)\n",
        "    main_ax.set_ylabel(\"Normalized intensity\",fontsize=18)\n",
        "\n",
        "    hist_size.boxplot(sizes)\n",
        "    hist_size.scatter([1 for x in range(len(sizes))],sizes)\n",
        "    hist_size.set_ylabel(\"Condensate size (µm)\",fontsize=18)\n",
        "    # hist_size.set_ylabel(\"Count\",fontsize=18)\n",
        "\n",
        "    hist_ecce.boxplot(ecc)\n",
        "    hist_ecce.scatter([1 for x in range(len(ecc))], ecc)\n",
        "    hist_ecce.set_ylabel(\"Eccentricity (a.u.)\",fontsize=18)\n",
        "    # hist_ecce.set_ylabel(\"Count\",fontsize=18)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def getEnergy(self):\n",
        "    coef_b = 0.1182024\n",
        "    coef_n = 2.12426\n",
        "    coef_a = 0.02712834\n",
        "    FirstTerm=(((0.5-coef_b)/((1-self.dip)-0.5))-1)\n",
        "    FirstTerm=float(f'{FirstTerm:.6f}')\n",
        "    SecondTerm=(1/coef_n)\n",
        "    SecondTerm=float(f'{SecondTerm:.6f}')\n",
        "    self.EnergyBarrier= (FirstTerm**SecondTerm)*coef_a \n",
        "\n",
        "  def saveReport(self,name,std=True):\n",
        "    \n",
        "    if std==True:\n",
        "      err1 = self.bleach_std\n",
        "      err2 = self.nonbleach_std\n",
        "    else:\n",
        "      err1 = self.bleach_sem\n",
        "      err2 = self.nonbleach_sem\n",
        "    \n",
        "    tosave = np.array([self.new_time,self.bleach_av,self.nonbleach_av,err1,err2]).T\n",
        "    np.savetxt(\"%s.csv\"%name, tosave, delimiter=',', header=\"Time,Bleach,Non-Bleach,Bleach_error,Non-Bleach_error\", \n",
        "                  comments=\"# average droplet size = %s, average droplet eccentricity = %s, dip = %s, dip std =%s, p value (Student test against dip in free solution) =%s, Energy barrier per molecule (kT) =%s \\n\"%(np.nanmean(self.droplet_size),np.nanmean(self.droplet_eccentricity),\n",
        "                  self.dip,self.dip_er,self.pvalue, self.EnergyBarrier))\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def register(im, nbleach,  nonbleach_mask,\n",
        "             extension=5, extension2=5,blur=1):\n",
        "    # Retrieve image size\n",
        "    width = im.shape[0]\n",
        "    height = im.shape[1]\n",
        "\n",
        "    # Construct rectangle around roi_mask (full)\n",
        "    xbleach = np.where(np.sum(nonbleach_mask > 0, axis=1) > 0)[0][0]\n",
        "    roi_right = np.where(np.sum(nonbleach_mask > 0, axis=1) > 0)[0][-1]\n",
        "    roi_left = xbleach - (roi_right-xbleach)\n",
        "    roi_top = np.where(np.sum(nonbleach_mask > 0, axis=0) > 0)[0][0]\n",
        "    roi_bottom = np.where(np.sum(nonbleach_mask > 0, axis=0) > 0)[0][-1]\n",
        "\n",
        "\n",
        "\n",
        "    target = getROI(im[:,:,0], xbleach - extension, roi_right + extension, roi_top - extension, roi_bottom + extension, blur)\n",
        "    target_full = getROI(im[:,:,0], roi_left - extension2, roi_right + extension2, roi_top - extension2, roi_bottom + extension2, blur)\n",
        "\n",
        "    tx_profile = np.mean(target, axis=1)\n",
        "    ty_profile = np.mean(target, axis=0)\n",
        "\n",
        "    xshift = np.zeros(im.shape[2])\n",
        "    yshift = np.zeros(im.shape[2])\n",
        "\n",
        "    for n in range(1, im.shape[2]):\n",
        "        source = getROI(im[:,:,n], xbleach + xshift[n-1] - extension, roi_right + extension + xshift[n-1] + extension,\n",
        "                        roi_top - extension + yshift[n-1] - extension, roi_bottom + extension + yshift[n-1] + extension, blur)\n",
        "        source_full = getROI(im[:,:,n], roi_left - extension2 + xshift[n-1], roi_right + extension2 + xshift[n-1],\n",
        "                             roi_top - extension2 + yshift[n-1], roi_bottom + extension2 + yshift[n-1], blur)\n",
        "        target_full = np.concatenate((target_full, source_full), axis=2)\n",
        "\n",
        "        sy_profile = np.mean(source[(1+extension):(source.shape[0]-extension), :], axis=0)\n",
        "        ys, _ = register_translation(ty_profile, sy_profile)\n",
        "\n",
        "        sx_profile = np.mean(source[:, (1+extension+ys):(source.shape[1]-extension+ys)], axis=1)\n",
        "        xs, _ = register_translation(tx_profile, sx_profile)\n",
        "\n",
        "        xshift[n] = xshift[n-1] + xs\n",
        "        yshift[n] = yshift[n-1] + ys\n",
        "\n",
        "    return [np.array([xshift, yshift]), target_full]\n",
        "\n",
        "\n",
        "def getROI(im, x1, x2, y1, y2, blur):\n",
        "    target = gaussian(im, sigma=blur)\n",
        "\n",
        "    target = target[max(0, x1):min(im.shape[0], x2), max(0, y1):min(im.shape[1], y2)]\n",
        "\n",
        "    left = max(1 - x1, 0)\n",
        "    right = max(x2 - im.shape[0], 0)\n",
        "    top = max(1 - y1, 0)\n",
        "    bottom = max(y2 - im.shape[1], 0)\n",
        "\n",
        "    target = np.pad(target, [(left, right), (top, bottom)], mode='constant', constant_values=np.nan)\n",
        "\n",
        "    return target\n",
        "\n",
        "\n",
        "\n",
        "def translate_mask(mask, shifts):\n",
        "    translated_mask = np.zeros_like(mask)\n",
        "    num_frames = mask.shape[2]\n",
        "\n",
        "    for n in range(num_frames):\n",
        "        shift_x = shifts[0][n]\n",
        "        shift_y = shifts[1][n]\n",
        "\n",
        "        translated_mask[:,:,n] = np.roll(mask[:,:,n], int(shift_x), axis=0)\n",
        "        translated_mask[:,:,n] = np.roll(translated_mask[:,:,n], int(shift_y), axis=1)\n",
        "\n",
        "    return translated_mask\n",
        "    \n",
        "\n",
        "def plot_mask(raw,mask,mask2=None,mask3=None):\n",
        "  # create edges array\n",
        "  #a = regionprops(mask)\n",
        "\n",
        "  edges1 = np.zeros_like(mask)\n",
        "  edges1 = np.ma.masked_where(edges1 == 0, edges1)\n",
        "  for ID in np.unique(mask)[1:]:\n",
        "    cell_mask = mask==ID\n",
        "    eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1)\n",
        "    edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
        "    edges1[edge_mask] = ID\n",
        "  try:\n",
        "    edges2 = np.zeros_like(mask2)\n",
        "    edges2 = np.ma.masked_where(edges2 == 0, edges2)\n",
        "    for ID in np.unique(mask2)[1:]:\n",
        "      cell_mask = mask2==ID\n",
        "      eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1)\n",
        "      edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
        "      edges2[edge_mask] = ID\n",
        "    edges2 = np.ma.masked_where(edges2 == 0, edges2)\n",
        "  except:\n",
        "    pass\n",
        "  try:\n",
        "    edges3 = np.zeros_like(mask3)\n",
        "    edges3 = np.ma.masked_where(edges3 == 0, edges3)\n",
        "    for ID in np.unique(mask3)[1:]:\n",
        "      cell_mask = mask3==ID\n",
        "      eroded_cell_mask = ndi.binary_erosion(cell_mask, iterations=1)\n",
        "      edge_mask = np.logical_xor(cell_mask, eroded_cell_mask)\n",
        "      edges3[edge_mask] = ID\n",
        "    edges3 = np.ma.masked_where(edges3 == 0, edges3)\n",
        "  except:\n",
        "    pass\n",
        "  #plot\n",
        "\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.imshow(raw, interpolation='none', cmap='gray')\n",
        "  plt.imshow(edges1,interpolation='none',cmap='Reds_r',alpha=1)\n",
        "  try:\n",
        "      plt.imshow(edges2,interpolation='none',cmap='Greens_r',alpha=1)\n",
        "  except:\n",
        "        pass\n",
        "  try:\n",
        "      plt.imshow(edges3,interpolation='none',cmap='Blues_r',alpha=1)\n",
        "  except:\n",
        "    pass\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3fDcRUy-L9s"
      },
      "outputs": [],
      "source": [
        "#@title Load data { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to load a tiff stack containing the half-FRAP experiment. Make sure that it has **only one color channel, that only one structure of interest has been bleached, and that the bleached half is located on the left**.*\n",
        "load_data=False #@param {type:\"boolean\"}\n",
        "example=True #@param {type:\"boolean\"}\n",
        "#@markdown  - by checking the \"example\" box, an example of a half-FRAP experiment will be loaded\n",
        "if example == True:\n",
        "  !git clone https://github.com/dymochro/MOCHA_example.git\n",
        "elif load_data == True:\n",
        "  uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5oumc5n_Y11"
      },
      "outputs": [],
      "source": [
        "#@title Specify parameters { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to confirm the parameters below that are used for the analysis:*\n",
        "time_resolution = 0.03 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the time resolution of the experiment (in seconds per frame)\n",
        "pixel_size = 0.04 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the size (in µm) of each pixel\n",
        "bleach_frame = 4 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the number of the first post-bleach frame\n",
        "sigma = 1.15 #@param {type:\"raw\"}\n",
        "#@markdown  - Pre-processing: Specify the sigma value for the Gaussian blur filter used for segmentation\n",
        "if load_data==True: \n",
        "  paths = [x for x in os.listdir('.') if x.endswith('.tif')]\n",
        "  img_path = paths[0]\n",
        "elif example==True:\n",
        "  img_path = \"MOCHA_example/Mocha_Example.tif\"\n",
        "  # img_path = \"Example_MF/example1.tif\"\n",
        "  # img_path = \"Example_MF/example2.tif\"\n",
        "\n",
        "exp=experiment(img_path,time_resolution,pixel_size,nbleach=bleach_frame,sigma=sigma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH7one4IUt7H"
      },
      "outputs": [],
      "source": [
        "#@title Segment the cell (or the nucleus) and the condensates { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to segment the entire cell (or nucleus), that is used as a reference for acquisition photobleaching, and the structure of interest.*\n",
        "#@markdown \n",
        "#@markdown **Do you want to segment the nucleus (or cell)?**\n",
        "#@markdown \n",
        "Segment_nucleus=True #@param {type:\"boolean\"}\n",
        "#@markdown *In some cases, nuclear segmentation can impair proper structure segmentation*\n",
        "#@markdown  - Specify a threshold for segmentation (a larger value corresponds to a more stringent segmentation), and min/max sizes (in pixels)\n",
        "nuclear_intensity_threshold = 0.025 #@param {type:\"raw\"}\n",
        "nuclear_min_size = 200 #@param {type:\"raw\"}\n",
        "nuclear_max_size = 2000000 #@param {type:\"raw\"}\n",
        "#@markdown \n",
        "#@markdown ---\n",
        "#@markdown \n",
        "#@markdown **Parameters for the segmentation of the structure of interest**\n",
        "structure_intensity_threshold = 1 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a scaling scaling factor to determine the intensity threshold for nuclear segmentation (a larger value corresponds to a more stringent segmentation)\n",
        "bleach_threshold = 0.9 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a scaling factor to segment the bleached structure of interest\n",
        "bleach_depth = 0.9 #@param {type:\"raw\"}\n",
        "#@markdown  - Specify a scaling factor to separate the bleached from the non-bleached half\n",
        "extra_pixels = 2 #@param {type:\"raw\"}\n",
        "#@markdown - specify the number of pixels between the bleached and the non-bleached half that are not considered for the analysis\n",
        "shift_bleach_limit = 0 #@param {type:\"raw\"}\n",
        "#@markdown - specify a number of pixels to shift the limit between bleached and non bleached halves.\n",
        "structure_min_size = 10 #@param {type:\"raw\"}\n",
        "#@markdown - specify the minimum size of segmented structures (in pixels)\n",
        "structure_max_size = 10000 #@param {type:\"raw\"}\n",
        "#@markdown - specify the maximum size of segmented structures (in pixels)\n",
        "\n",
        "if Segment_nucleus==True:\n",
        "    exp.segment_cell(thr_nuc=nuclear_intensity_threshold,nucsize_min=nuclear_min_size,nucsize_max=nuclear_max_size)\n",
        "    exp.segment_condensate(thr_cond=structure_intensity_threshold,use_nuc_mask=True,condsize_min=structure_min_size,condsize_max=structure_max_size)\n",
        "    exp.getBleachedmask(alpha=bleach_threshold,sigma_b=1,beta=bleach_depth,extra_pix=extra_pixels,shift_x=shift_bleach_limit)\n",
        "    plot_mask(exp.bleach_img,exp.nucmask,exp.bleachmask,exp.nonbleachmask)\n",
        "else:\n",
        "    exp.segment_condensate(thr_cond=structure_intensity_threshold,use_nuc_mask=False,condsize_min=structure_min_size,condsize_max=structure_max_size)\n",
        "    exp.getBleachedmask(alpha=bleach_threshold,sigma_b=1,beta=bleach_depth,extra_pix=extra_pixels,shift_x=shift_bleach_limit)\n",
        "    plot_mask(exp.bleach_img,exp.bleachmask,exp.nonbleachmask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QNfBPqjWAgZ"
      },
      "outputs": [],
      "source": [
        "#@title Calculate normalized half-FRAP curves { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to retrieve the raw intensities in both halves and to perform the corresponding normalization*\n",
        "Normalize_by_total_intensity=True #@param {type:\"boolean\"}\n",
        "#@markdown  - Specify if total intensity will be used for normalization\n",
        "exp.getIntensities()\n",
        "exp.getNormalizedTraces(byTotal=Normalize_by_total_intensity)\n",
        "exp.plotNormalizationProcess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTJfHq-3JnnV"
      },
      "outputs": [],
      "source": [
        "#@title Save normalized half-FRAP curves { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to confirm the name of the .csv file that will be downloaded to your computer.*\n",
        "name = \"example_2\" #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the name of the data set\n",
        "exp.saveData(name)\n",
        "files.download(\"%s.csv\"%name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JicQPoBp2sG"
      },
      "outputs": [],
      "source": [
        "#@title Remove data to continue the analysis { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to delete the current data set before uploading/analyzing the next one*\n",
        "!rm -r *"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OPy5e1kvlXdW"
      },
      "source": [
        "## **Part II: Analysis of dataset with normalized curves**\n",
        "*After having analyzed the individual experiments using the code above, use the steps below to upload the respective csv files (containing analyzed replicates for the same condition) to average them, determine the dip depth, and test if molecules undergo LLPS or ICBS*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVaB44IUj2GZ"
      },
      "outputs": [],
      "source": [
        "#@title Load .csv files containing individual replicates { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to select all the .csv files that contain replicates analyzed according to the steps indicated above*\n",
        "!rm -r *\n",
        "uploaded = files.upload()\n",
        "# check all files with .csv extension\n",
        "\n",
        "path = os.getcwd()\n",
        "alldata=MOCHAdataset(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Explore the data { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to plot and explore all your data*\n",
        "#@markdown \n",
        "#@markdown In the following plot, top panels despict the normalized intensity non-bleached half \n",
        "#@markdown and bottom panels the normalized intensity bleached half. The first column shows the data vs the real time, while the second column.\n",
        "#@markdown shows the data vs the normalized time. This time is normalized by the size of the structure of interest. Although the dip is independent of the size of the structure,\n",
        "#@markdown the time point at which this dip is maximum scales with the size of the structure (see supplementary figure 7 in <a href=\"https://www.nature.com/articles/s41467-022-35430-y\">Muzzopappa et al., 2022</a>).\n",
        "#@markdown Using this time axis to average the data will correct the effect of the different structure sizes.\n",
        "#@markdown Finally, the last column shows the intensities of bleached and non bleached halves, corrected by the bound fraction.\n",
        "\n",
        "alldata.explore_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CREv6HxmdxD"
      },
      "outputs": [],
      "source": [
        "#@title Run analysis and plot data { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to run the analysis with the options below*\n",
        "Normalized_time = True #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if normalized time should be used to average data (after aggregating the data, the time axis is restored to the real values).\n",
        "bound_fraction = False #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if the curves should be normalized by the bound (immobile) fraction\n",
        "use_std = True #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if the standard deviation (true) or the standard error of the mean (false) should be plotted\n",
        "select_by_eccentricity = False #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if you want to select a subset of the data based on the eccentricity\n",
        "min_max_eccentricity = \"0,1\" #@param {type:\"raw\"}\n",
        "#@markdown - Specify the range (minimum and maximum) of eccentricity to select a subset of data\n",
        "select_by_size = False #@param {type:\"boolean\"}\n",
        "#@markdown - Specify if you want to select a subset of the data based on the eccentricity\n",
        "min_max_size = \"0,3\" #@param {type:\"raw\"}\n",
        "#@markdown - Specify the range (minimum and maximum) of radii (in µm) to select a subset of data\n",
        "filter_window = 21 #@param {type:\"raw\"}\n",
        "#@markdown - Specify the window length for the Savitzky-Golay filter that is used to smooth the curve for the non-bleached half \n",
        "order_polynomial = 2 #@param {type:\"raw\"}\n",
        "#@markdown - Specify the polynomial order for the Savitzky-Golay filter that is used to smooth the curve for the non-bleached half \n",
        "\n",
        "min_ecc = float(min_max_eccentricity.split(\",\")[0])\n",
        "max_ecc = float(min_max_eccentricity.split(\",\")[1])\n",
        "\n",
        "min_size = float(min_max_size.split(\",\")[0])\n",
        "max_size = float(min_max_size.split(\",\")[1])\n",
        "\n",
        "alldata.getAverage(use_norm_time = Normalized_time,bound_fraction=bound_fraction,selection_ecc=select_by_eccentricity,min_ecc=min_ecc,max_ecc=max_ecc,\n",
        "                                selection_size=select_by_size,min_size=min_size,max_size=max_size)\n",
        "alldata.makeNicePlot(std=use_std,sg_window=filter_window,poly_order = order_polynomial,selection_ecc=select_by_eccentricity,min_ecc=min_ecc,max_ecc=max_ecc,\n",
        "                                selection_size=select_by_size,min_size=min_size,max_size=max_size)\n",
        "alldata.getEnergy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wQgjcWgtG4n"
      },
      "outputs": [],
      "source": [
        "#@title Interpret the result { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to interpret the result*\n",
        "print(\"FINAL REPORT:\")\n",
        "if alldata.pvalue <= 0.01:\n",
        "  print(\"The dip depth of the sample was significantly higher than the dip depth expected for freely diffusing molecules (p<0.01)\")\n",
        "  print(\"This indicates that the molecules of interest feel a barrier at the interface of the structure of interest, which is a hallmark of LLPS.\")\n",
        "  print(\"By using the calibration curve from Muzzopappa et al. 2022, the apparent energy barrier per molecule determined from the dip depth is %s kT\"%\"{:.2E}\".format(Decimal(alldata.EnergyBarrier)))\n",
        "else:\n",
        "  print(\"The dip depth (%s) is not significantly larger than the dip depth seen for freely diffusing molecules.\"%alldata.dip)\n",
        "  print(\"This indicates that the molecules of interest do not feel any barrier at the interface of the structure of interest, indicating that molecules undergo ICBS.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Save the results { display-mode: \"form\" }\n",
        "#@markdown *Click on the arrow to generate a full report of the data analysis*\n",
        "name = \"example_2\" #@param {type:\"raw\"}\n",
        "#@markdown  - Specify the name of the data report\n",
        "alldata.saveReport(name,std=use_std)\n",
        "files.download(\"%s.csv\"%name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
